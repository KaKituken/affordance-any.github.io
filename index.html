<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Nerfies: Deformable Neural Radiance Fields</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <div class="navbar-item has-dropdown is-hoverable">
        <!-- <a class="navbar-link">
          More Research
        </a> -->
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Affordance-Aware Object Insertion via Mask-Aware Dual Diffusion</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://kakituken.github.io/home/">Jixuan He<sup>*</sup></a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://li-wanhua.github.io/">Wanhua Li<sup>*</sup></a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://yeliu.dev/">Ye Liu</a><sup>2,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/site/jskimcv/">Junsik Kim</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://donglaiw.github.io/">Donglai Wei</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://vcg.seas.harvard.edu/people/">Hanspeter Pfister</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Cornell Tech,</span>
            <span class="author-block"><sup>2</sup>Harvard University,</span>
            <span class="author-block"><sup>3</sup>The Hong Kong Polytechnic University,</span>
            <span class="author-block"><sup>4</sup>Boston College,</span>
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-desktop"></i>
                  </span>
                  <span>Demo</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/KaKituken/affordance-aware-any"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <img id="teaser" src="./static/images/teaser.png"> -->
      <video autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/video_demo.mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Madd</span> performs affordance-aware object insertion conditioning on different position prompts, including points, bounding boxes, masks, and even null prompts.
      </h2>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            As a common image editing operation, image composition involves integrating foreground objects into background scenes. 
            In this paper, we expand the application of the concept of <i>Affordance</i> from human-centered image composition tasks to a more general 
            object-scene composition framework, addressing the complex interplay between foreground objects and background scenes. 
            
          </p>
          <p>
            Following the principle of <i>Affordance</i>, we define the affordance-aware object insertion task, which aims to 
            seamlessly insert any object into any scene with various position prompts. 
            To address the limited data issue and incorporate this task, we constructed the SAM-FB dataset, which contains over 3 million examples across more than 3,000 object categories. 
            Furthermore, we propose the <b>M</b>ask-<b>A</b>ware <b>D</b>ual <b>D</b>iffusion (<span class="dnerf">Madd</span>) model, which utilizes 
            a dual-stream architecture to simultaneously denoise the RGB image and the insertion mask. 
          </p>
          <p>
            By explicitly modeling the insertion mask in the diffusion process, <span class="dnerf">Madd</span>  effectively facilitates the notion of affordance. 
            Extensive experimental results show that our method outperforms the state-of-the-art methods and exhibits strong generalization performance on in-the-wild images. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Paper video. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Affordance-aware Insertion</h2>
        <div class="">
           <img id="teaser" src="./static/images/teaser.png">
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Model Architecture</h2>
        <div>
          <img src="./static/images/model.png">
        </div>
        <h2 class="has-text-justified">
          The framework of <span class="dnerf">Madd</span>. Foreground objects are encoded using a DINOv2 encoder, serving as the guidance signal through the cross-attention mechanism. 
          The position prompt encoder unifies different types of position prompts, which are then concatenated with the latent mask <b>m</b><sub>t</sub>. 
          The background is encoded using a VAE encoder and then concatenated with the latent image <b>z</b><sub>t</sub>. 
          We use a dual branch structure to denoise RGB image <b>z</b> and object mask <b>m</b> simultaneously.
        </h2>
      </div>
    </div>

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">More Visualization</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">SAM-FB Test Set</h3>
        <div class="content has-text-justified">
          <p>
            We presents the visualization results on the SAM-FB test set. In each group, the leftmost image depicts the back-
            ground marked with a position prompt. Our <span class="dnerf">Madd</span> predicts the RGB image and mask of the inserted object, which
            are shown in the last two images of each group.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <img src="./static/images/SAM-FB.png">
        </div>
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">In-the-wild Images</h3>
        <div class="content has-text-justified">
          <p>
            Example of in-the-wild insertion results with details. 
            <span class="dnerf">Madd</span> could keep the appearance better and adjust the foreground's properties better compared with different baseline models
             on both common and uncommon objects. In the last row, <span class="dnerf">Madd</span> generated reasonable insertion when provided ambiguous prompts.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/compare_supp.png">
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Works</h2>

        <div class="content has-text-justified">
          <ul>
            <li>Sumith Kulal, Tim Brooks, Alex Aiken, Jiajun Wu, Jimei Yang, Jingwan Lu, Alexei A Efros, and Krishna Kumar Singh. 
              <a href="https://arxiv.org/abs/2304.14406">Putting people in their place: Affordance-aware human insertion into scenes.</a> In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</li>
            <li>Binxin Yang, Shuyang Gu, Bo Zhang, Ting Zhang, Xuejin Chen, Xiaoyan Sun, Dong Chen, and Fang Wen. 
              <a href="https://arxiv.org/abs/2211.13227"> Paint by example: Exemplar-based image editing with diffusion models.</a> In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</li>
            <li>Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jian-wei Yang, Jianfeng Gao, Chunyuan Li, and Yong Jae Lee. 
              <a href="https://arxiv.org/abs/2301.07093">Gligen: Open-set grounded text-to-image generation.</a> In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</li>
            <li>Yizhi Song, Zhifei Zhang, Zhe Lin, Scott Cohen, Brian Price, Jianming Zhang, Soo Ye Kim, and Daniel Aliaga. 
              <a href="https://arxiv.org/abs/2212.00932">ObjectStitch: Object compositing with diffusion model.</a>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</li>
          </ul>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre>
      <!-- <code>@article{park2021nerfies,
          author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
          title     = {Nerfies: Deformable Neural Radiance Fields},
          journal   = {ICCV},
          year      = {2021},
        }
      </code> -->
    </pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website inspired by Nerfies and and adapted from the following source code.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
